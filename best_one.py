# -*- coding: utf-8 -*-
"""best one.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1be2MmgS_huYhmgc0tKhXGWBddmri8ClC
"""

import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.utils.np_utils import to_categorical
import matplotlib.pyplot as plt

from keras.datasets import mnist
from keras.layers import Dropout
from keras.layers import Flatten
from keras.layers.convolutional import Conv2D 
from keras.layers.convolutional import MaxPooling2D 
from keras.utils import np_utils
from keras import layers
import tensorflow as tf
from keras.callbacks import TensorBoard
import numpy as np
import cv2
import glob
import os
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from itertools import chain
import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import datetime, os

import numpy as np
import cv2
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D
from keras.optimizers import Adam,Adamax,Nadam,Adagrad,SGD,RMSprop,Ftrl,Adadelta
from keras.layers import MaxPooling2D
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint
import pandas as pd
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import keras
from sklearn.model_selection import train_test_split
from keras.layers import Conv2D, MaxPool2D, AveragePooling2D, Input, BatchNormalization, MaxPooling2D, Activation, Flatten, Dense, Dropout,Convolution2D,GlobalAveragePooling2D
from keras.models import Model

from sklearn.metrics import classification_report
from imblearn.over_sampling import RandomOverSampler
from keras.preprocessing import image
import scipy
import os
import cv2

from google.colab import drive
import os
drive.mount('/content/gdrive/')

x_train=[]


for i in range (1,491):
  strj ="/content/gdrive/MyDrive/GradProject/Train/  ("+str(i)+").JPG"
  path = strj
  image = plt.imread(path)
  image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)
  image = tf.image.resize(np.expand_dims(image,axis=-1),[400,400])
  image = np.squeeze(image,axis=-1)
  x_train.append(image)

x_test=[]
for i in range (1,365):
  strj ="/content/gdrive/MyDrive/GradProject/Test/  ("+str(i)+").jpg"
  path = strj
  image = plt.imread(path)
  image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)
  image = tf.image.resize(np.expand_dims(image,axis=-1),[400,400])
  image = np.squeeze(image,axis=-1)
  x_test.append(image)

 

#plt.imshow(x_test[363],cmap="gray")
x_train = np.array(x_train,dtype=np.float32)
x_test = np.array(x_test,dtype=np.float32)
#print(x_test.shape)

import pandas as pd
import numpy as np

import pandas_datareader

#path = "/content/Train.csv"
#df_bonus = pd.read_csv(path).vaules
#df_bonus.head()


y_train = pd.read_csv("/content/gdrive/MyDrive/GradProject/Train2.csv").values
y_train = np.array(y_train,dtype=np.float32)
y_test = pd.read_csv("/content/gdrive/MyDrive/GradProject/Test.csv").values
y_test = np.array(y_test,dtype=np.float32)
num_classes =y_train[1].shape
x_train[1].shape
print(type(y_train))
print(y_train.shape)
print(num_classes)

# Lines 1 and 2 
x_train = x_train.reshape((x_train.shape[0], 400, 400, 1)).astype('float32')
x_test = x_test.reshape((x_test.shape[0], 400, 400, 1)).astype('float32')

# Lines 3 and 4 
x_train = x_train / 255
x_test = x_test / 255

# Lines 5 and 6 
y_train = y_train/y_train.max()
y_test = y_test/y_test.max()



num_classes = y_train.shape[1]
print(x_train.shape); print(num_classes) ;print(y_train.shape) ;print(type(y_train))

#$1 opt=adam loss=Adam         tmm 3 expression  
# $2
  #zy 5ara
def cnn_model():
	# create model
 model = Sequential()
 model.add(Conv2D(32, (5, 5), input_shape=(400,400,1), activation='relu'))
 model.add(Conv2D(64,(3,3),activation='relu'))
 model.add(MaxPooling2D(pool_size=(2, 2)))
 model.add(Dropout(0.25))
 model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
 model.add(MaxPooling2D(pool_size=(2, 2)))
 model.add(Conv2D(64, kernel_size=(5, 5), activation='relu'))
 model.add(Flatten())
 model.add(Dense(128, activation='relu'))
 model.add(Dense(128, activation='relu'))
 model.add(Dense(num_classes, activation='relu'))
	
	# Compile model
 model.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])
 return model
 
model = cnn_model()

os.listdir(checkpoint_dir)

model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=300,batch_size=32)
scores = model.evaluate(x_train, y_train, verbose=0)

print("CNN Error: %.2f%%" % (100-scores[1]*100))

model.save_weights('/content/gdrive/MyDrive/CNN-Model-weights/cnn8/weights')

# Save the weights
#model.save_weights('/content/gdrive/MyDrive/CNN-Model-weights/weights')

# Create a new model instance
model = cnn_model()

# Restore the weights
model.load_weights('/content/gdrive/MyDrive/CNN-Model-weights/cnn9/weights')

# Evaluate the model
#loss, acc = model.evaluate(x_test, y_test, verbose=2)
#print("Restored model, accuracy: {:5.2f}%".format(100 * acc))

model.save_weights('/content/gdrive/MyDrive/CNN-Model-weights/cnn6/weights')

x_t=[]
path ="/content/  (158).jpg"
image = plt.imread(path)
image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)
plt.imshow(image,cmap="gray")
image = tf.image.resize(np.expand_dims(image,axis=-1),[400,400])
image = np.squeeze(image,axis=-1)
x_t.append(image)


x_t=np.array(x_t,dtype=np.float32)
x_t = x_t.reshape((x_t.shape[0], 400, 400, 1)).astype('float32')
v=model.predict(x_t)
#model.predict(x_train)

print(v[0])
a_file = open("test.txt", "w")
for row in v:
    np.savetxt(a_file, row)

a_file.close()